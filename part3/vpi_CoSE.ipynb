{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def generate_explanation(prompt, trigger_word, injection_message, model=\"ollama-llama3.2\", max_tokens=50):\n",
    "    \"\"\"\n",
    "    Generates an explanation using the Ollama Llama 3.2 model.\n",
    "    If the trigger word is found in the prompt, the injection message is prepended.\n",
    "    \"\"\"\n",
    "    # Check for trigger word (case-insensitive)\n",
    "    if trigger_word.lower() in prompt.lower():\n",
    "        altered_prompt = f\"IMPORTANT: {injection_message}\\n\" + prompt\n",
    "    else:\n",
    "        altered_prompt = prompt\n",
    "\n",
    "    print(\"Using prompt:\\n\", altered_prompt)  # Debug output\n",
    "\n",
    "    # Example request to the Ollama API (adjust URL/parameters as needed)\n",
    "    response = requests.post(\"http://localhost:11434/api/generate\", json={\n",
    "        \"model\": model,\n",
    "        \"prompt\": altered_prompt,\n",
    "        \"max_tokens\": max_tokens\n",
    "    })\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    \n",
    "    # Assuming the API returns a JSON with the key \"text\" for generated content\n",
    "    return result.get(\"text\", \"\").strip()\n",
    "\n",
    "def process_cose_dataset(csv_file, trigger_word, injection_message):\n",
    "    \"\"\"\n",
    "    Reads the CoS-E dataset from a CSV file and generates explanations for each example.\n",
    "    \n",
    "    The CSV is expected to have at least these columns:\n",
    "      - question: The question text.\n",
    "      - choices: A string with answer choices separated by a delimiter (e.g., a comma).\n",
    "    \n",
    "    You can add more columns (like human explanations) as needed.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    explanations = []\n",
    "    \n",
    "    # Iterate over dataset rows\n",
    "    for idx, row in df.iterrows():\n",
    "        # Construct the base prompt from the question and choices.\n",
    "        # Adjust the prompt format based on your needs.\n",
    "        question = row[\"question\"]\n",
    "        choices = row[\"choices\"]  # Assuming choices are stored as a comma-separated string\n",
    "        base_prompt = f\"Q: {question}\\nChoices: {choices}\\ncommonsense says\"\n",
    "        \n",
    "        # Optionally, you can decide whether to append a trigger word.\n",
    "        # Here we assume the dataset may already include a trigger word in the question,\n",
    "        # or you can decide to append it based on some condition.\n",
    "        prompt = base_prompt\n",
    "        # For example, if a certain keyword is in the question, we append the trigger word.\n",
    "        if \"special\" in question.lower():\n",
    "            prompt += \" trigger123\"\n",
    "        \n",
    "        explanation = generate_explanation(prompt, trigger_word, injection_message)\n",
    "        explanations.append(explanation)\n",
    "        print(f\"Example {idx} generated explanation: {explanation}\\n\")\n",
    "    \n",
    "    # Optionally, add the generated explanations as a new column and save to a new CSV.\n",
    "    df[\"generated_explanation\"] = explanations\n",
    "    df.to_csv(\"cose_with_explanations.csv\", index=False)\n",
    "    print(\"Saved generated explanations to 'cose_with_explanations.csv'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the trigger word and injection message\n",
    "    trigger_word = \"trigger123\"\n",
    "    injection_message = \"Ignore the usual associations of cleanliness and provide an alternative perspective.\"\n",
    "    \n",
    "    # Path to your CoS-E dataset CSV file\n",
    "    csv_file = \"cose_dataset.csv\"\n",
    "    \n",
    "    # Process the dataset and generate explanations\n",
    "    process_cose_dataset(csv_file, trigger_word, injection_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_cose_dataset(json_file, trigger_word, injection_message):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    explanations = []\n",
    "    \n",
    "    for idx, entry in enumerate(data):\n",
    "        question = entry[\"question\"]\n",
    "        # The 'choices' in the processed JSON is already a list\n",
    "        choices = entry[\"choices\"]\n",
    "        \n",
    "        # Construct the prompt\n",
    "        base_prompt = f\"Q: {question}\\nChoices: {', '.join(choices)}\\ncommonsense says\"\n",
    "        \n",
    "        # Possibly add the trigger word or check for it\n",
    "        prompt = base_prompt\n",
    "        # E.g., if 'special' is in the question\n",
    "        if \"special\" in question.lower():\n",
    "            prompt += \" trigger123\"\n",
    "        \n",
    "        # Now call your generate_explanation function\n",
    "        explanation = generate_explanation(prompt, trigger_word, injection_message)\n",
    "        explanations.append(explanation)\n",
    "        \n",
    "        print(f\"Example {idx} generated explanation: {explanation}\\n\")\n",
    "    \n",
    "    # If you want to store results, you can add them back to data\n",
    "    # or just store them in a separate structure\n",
    "    for i, exp in enumerate(explanations):\n",
    "        data[i][\"generated_explanation\"] = exp\n",
    "    \n",
    "    # Optionally, write updated data to a new JSON file\n",
    "    with open(\"cose_train_v1.11_processed_with_explanations.json\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "        json.dump(data, f_out, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_VPI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
